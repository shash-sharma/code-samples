{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asalcedo31/CSC2516_project/blob/master/initial_meta_pruning_framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WcnGoj4y0dVu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fmjGlo3V0jCd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bd4d138a-b8fe-4d84-b194-4e212ac414ef"
      },
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=5,\n",
        "                                         shuffle=False, num_workers=0)\n",
        "# _,trainset = torch.utils.data.random_split(trainset,(49200,800))\n",
        "# _,trainset = torch.utils.data.random_split(trainset,(49995,5))\n",
        "# print(trainset.__len__())\n",
        "\n",
        "# train_data, val_data = torch.utils.data.random_split(trainset,(int(0.8*len(trainset)),int(0.2*len(trainset))))\n",
        "# print(train_data.__len__(),val_data.__len__() )\n",
        "\n",
        "# trainloader = torch.utils.data.DataLoader(train_data, batch_size=5,\n",
        "#                                           shuffle=True, num_workers=0)\n",
        "# valloader = torch.utils.data.DataLoader(val_data, batch_size=5,\n",
        "#                                           shuffle=True, num_workers=0)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "15v78wBX0l32",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# image_datasets= {'train': train_data,'val': val_data}\n",
        "# dataloaders = {'train': trainloader, 'val': valloader}\n",
        "\n",
        "# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "# class_names = image_datasets['train'].classes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u6pkokkh0mx_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def freeze_layers(model_ft, exclude=[]):\n",
        "#   children = list(model_ft.named_children())\n",
        "  for name,param in model_ft.named_parameters():   \n",
        "    if(name not in  exclude):\n",
        "      param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7PENRAKM0pLT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def countNonZeroWeights(model):\n",
        "    nonzeros = 0\n",
        "    weights = 0\n",
        "    for name,param in model.named_parameters():\n",
        "        if param is not None:\n",
        "            nonzeros += torch.sum((param != 0).int()).data[0]\n",
        "            weights += torch.sum(param).data[0]\n",
        "    \n",
        "    return nonzeros, weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dyXlRGiw0raM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def set_threshold(model,prop=0.05):\n",
        "  for child in model.named_children():    \n",
        "    for child in child[1].named_children():\n",
        "#       print(child)\n",
        "      if type(child[1]) == MaskedLinear or type(child[1]) == MaskedConv: \n",
        "        child[1].set_threshold(prop=prop)\n",
        "        print(\"layer {}  new threshold {:.4f}\".format(child[0], child[1].threshold))        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ear7nRQY0wwC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model_prune(model, dloaders, dataset_sizes, criterion, optimizer, scheduler,prop=0.05, num_epochs=25, device='cuda',):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    print(len(dloaders['train']))\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  # Set model to training mode\n",
        "                data_idx = 0\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                data_idx = 1\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            i=0\n",
        "      \n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dloaders[phase]:               \n",
        "#                 print(\"batch {} phase {}\".format(i, phase))\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                i+=1\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                           \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            if epoch % 5 == 0 and phase == 'train':\n",
        "              set_threshold(model,prop=prop)   \n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FS6V4Olo00JW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Masked:\n",
        "  def make_mask(self, threshold,mask=None):\n",
        "    if mask is None:\n",
        "      print(\"new mask\",device)\n",
        "      self.mask = torch.ones(self.weight.size(), requires_grad=False).to(device)\n",
        "    else:\n",
        "      self.mask = mask      \n",
        "    self.zeros = torch.zeros(self.weight.size(), requires_grad=False).to(device)\n",
        "    self.threshold = threshold\n",
        "  def set_threshold(self,prop=0.05):\n",
        "    unique_weights = torch.unique(self.weight*self.mask)\n",
        "    mask_size = self.mask.reshape(-1).size()[0]\n",
        "#     mask_size = mask_size[0]*mask_size[1]\n",
        "    mask_nonzero = torch.sum(self.mask.view([mask_size]))\n",
        "    mask_total = mask_size\n",
        "    print('nonzero proportion: {:.4f}'.format(mask_nonzero/mask_total))\n",
        "    self.threshold = torch.max(torch.topk(torch.abs(unique_weights),int(prop*unique_weights.size()[0]),largest=False)[0])    \n",
        "  def make_threshold_mask(self):\n",
        "    self.mask = torch.where(torch.abs(self.weight) >= self.threshold,self.mask,self.zeros).to(device)\n",
        "#     self.mask.requires_grad_(requires_grad=False)\n",
        "  def mask_weight(self):\n",
        "    self.weight = torch.nn.Parameter(self.weight*self.mask).to(device)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QtGNlj9j04hZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MaskedLinear(torch.nn.Linear,Masked):\n",
        "  def __init__(self, in_features, out_features, bias=True, threshold=0.001,mask=None):\n",
        "    super(MaskedLinear, self).__init__(in_features,out_features)\n",
        "    self.make_mask(threshold,mask)\n",
        "  def forward(self, input):\n",
        "    self.make_threshold_mask()\n",
        "    self.mask_weight()\n",
        "#     print(self.mask[125:135,125:135])\n",
        "#     print(self.weight[125:135,125:135])\n",
        "    return F.linear(input, self.weight, self.bias)\n",
        "\n",
        "class MaskedConv(torch.nn.Conv2d,Masked):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride,\n",
        "                 padding, dilation, groups, bias=True,threshold=0.0001):\n",
        "    super(MaskedConv,self).__init__(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
        "    self.make_mask(threshold)    \n",
        "  def forward(self, input):\n",
        "    self.mask_weight()\n",
        "    return F.conv2d(input, self.weight, self.bias, self.stride,\n",
        "                    self.padding, self.dilation, self.groups)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iJeDMbDw06i2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mask_network(network,layers_to_mask, threshold=0.002, random_init=False, bias=True,masks=None):\n",
        "  \"\"\"\"\n",
        "  replaces linear layers with masked linear layers\n",
        "  network is the initial sequential container\n",
        "  layers is a list of layers to mask\n",
        "  random init is a logical indicating whether to preserve the initial weights or to modify them\n",
        "  \"\"\"\n",
        "  for name,layer in network.named_children():   \n",
        "    if int(name) in layers_to_mask:\n",
        "      layer_mask = None\n",
        "      if masks is not None:\n",
        "        if name in masks:\n",
        "          layer_mask = masks.get(name)      \n",
        "      if type(layer)== torch.nn.Linear:\n",
        "        masked_layer = MaskedLinear(layer.in_features, layer.out_features, bias=bias,threshold=threshold,mask=layer_mask)\n",
        "      elif type(layer)== torch.nn.Conv2d:\n",
        "        masked_layer = MaskedConv(layer.in_channels, layer.out_channels, layer.kernel_size, layer.stride, layer.padding, layer.dilation,layer.groups, bias=bias, threshold=threshold)\n",
        "      if random_init != True:\n",
        "        masked_layer.weight = copy.deepcopy(layer.weight)\n",
        "        masked_layer.bias = copy.deepcopy(layer.bias)\n",
        "      network[int(name)] = masked_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GShMvVfL0-mQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5147
        },
        "outputId": "60eeac54-70c5-487e-de3a-23eaea9822a1"
      },
      "cell_type": "code",
      "source": [
        "def train_meta_prune(model,trainset, outer_steps, num_samples=800, device='cuda'):\n",
        "  mask_dict = {'0':torch.ones(model.classifier[0].weight.size()).to(device)}\n",
        "  shuffled_train = torch.utils.data.RandomSampler(trainset)\n",
        "  train_sample_list = list(torch.utils.data.BatchSampler(shuffled_train,num_samples,False))\n",
        "  shuffled_train = [x for x in shuffled_train]\n",
        "  for i in range(outer_steps):\n",
        "#     train_sample = [trainset[j] for j in train_sample_list[i]] \n",
        "    \n",
        "#     print(len(train_sample))\n",
        "    _,train_sample = torch.utils.data.random_split(trainset,(49200,800))\n",
        "    train_data, val_data = torch.utils.data.random_split(train_sample,(int(0.8*num_samples),int(0.2*num_samples)))\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(train_data, batch_size=5,\n",
        "                                            shuffle=True, num_workers=0)\n",
        "    valloader = torch.utils.data.DataLoader(val_data, batch_size=5,\n",
        "                                            shuffle=True, num_workers=0)\n",
        "    \n",
        "    subdataloaders = {'train': trainloader, 'val': valloader}\n",
        "    image_datasets= {'train': train_data,'val': val_data}\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "    \n",
        "    model_ft = models.vgg16(pretrained=True)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    # Decay LR by a factor of 0.1 every 7 epochs\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "    # freeze_layers(model_ft.features, exclude=['28.weight'])\n",
        "    freeze_layers(model_ft.features)   \n",
        "    mask_network(model_ft.classifier,[0],threshold=0.0001,masks=mask_dict)\n",
        "    model_ft = train_model_prune(model_ft, subdataloaders, dataset_sizes, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=10, prop=0.1)\n",
        "    mask_dict = {'0':model_ft.classifier[0].mask}\n",
        "#     set_threshold(model_ft)\n",
        "\n",
        "#     cost = meta_objective({'train':trainloader, 'val':valoader}, model, optimizer, inner_epochs)\n",
        "\n",
        "\n",
        "model_ft = models.vgg16(pretrained=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "train_meta_prune(model_ft,trainset,5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 3.1251 Acc: 0.2531\n",
            "nonzero proportion: 0.9832\n",
            "layer 0  new threshold 0.0005\n",
            "val Loss: 1.6068 Acc: 0.4438\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 1.9109 Acc: 0.4062\n",
            "val Loss: 1.7005 Acc: 0.4500\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 1.7182 Acc: 0.4547\n",
            "val Loss: 2.1942 Acc: 0.3250\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 1.8547 Acc: 0.4031\n",
            "val Loss: 1.6160 Acc: 0.4813\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 1.6726 Acc: 0.4766\n",
            "val Loss: 1.3715 Acc: 0.5125\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 1.6214 Acc: 0.4906\n",
            "nonzero proportion: 0.9213\n",
            "layer 0  new threshold 0.0009\n",
            "val Loss: 1.5461 Acc: 0.5000\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 1.5801 Acc: 0.4953\n",
            "val Loss: 1.5283 Acc: 0.5062\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 1.3409 Acc: 0.5469\n",
            "val Loss: 1.3989 Acc: 0.4625\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 1.2761 Acc: 0.5594\n",
            "val Loss: 1.3815 Acc: 0.5000\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 1.2496 Acc: 0.5922\n",
            "val Loss: 1.2949 Acc: 0.4938\n",
            "\n",
            "Training complete in 1m 42s\n",
            "Best val Acc: 0.512500\n",
            "128\n",
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 3.1859 Acc: 0.2531\n",
            "nonzero proportion: 0.8575\n",
            "layer 0  new threshold 0.0013\n",
            "val Loss: 1.7815 Acc: 0.3750\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 1.8655 Acc: 0.3844\n",
            "val Loss: 1.6593 Acc: 0.4500\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 1.6936 Acc: 0.4266\n",
            "val Loss: 1.5711 Acc: 0.4938\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 1.6877 Acc: 0.4750\n",
            "val Loss: 1.7810 Acc: 0.3875\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 1.6699 Acc: 0.4516\n",
            "val Loss: 1.6736 Acc: 0.4500\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 1.6280 Acc: 0.4797\n",
            "nonzero proportion: 0.7911\n",
            "layer 0  new threshold 0.0017\n",
            "val Loss: 1.5630 Acc: 0.4688\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 1.5375 Acc: 0.4875\n",
            "val Loss: 1.5064 Acc: 0.4313\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 1.3384 Acc: 0.5547\n",
            "val Loss: 1.2918 Acc: 0.5500\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 1.2767 Acc: 0.5578\n",
            "val Loss: 1.2190 Acc: 0.5250\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 1.2097 Acc: 0.5687\n",
            "val Loss: 1.3783 Acc: 0.5250\n",
            "\n",
            "Training complete in 1m 43s\n",
            "Best val Acc: 0.550000\n",
            "128\n",
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 3.1789 Acc: 0.2359\n",
            "nonzero proportion: 0.7276\n",
            "layer 0  new threshold 0.0021\n",
            "val Loss: 1.8236 Acc: 0.3813\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 1.7978 Acc: 0.4000\n",
            "val Loss: 1.6185 Acc: 0.4375\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 1.7686 Acc: 0.4484\n",
            "val Loss: 1.4710 Acc: 0.5188\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 1.6872 Acc: 0.4391\n",
            "val Loss: 1.5481 Acc: 0.4688\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 1.5940 Acc: 0.4922\n",
            "val Loss: 1.6682 Acc: 0.4813\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 1.6373 Acc: 0.4703\n",
            "nonzero proportion: 0.6666\n",
            "layer 0  new threshold 0.0025\n",
            "val Loss: 1.7596 Acc: 0.4438\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 1.5737 Acc: 0.4891\n",
            "val Loss: 1.5604 Acc: 0.4688\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 1.3507 Acc: 0.5422\n",
            "val Loss: 1.3942 Acc: 0.5250\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 1.2854 Acc: 0.5656\n",
            "val Loss: 1.2160 Acc: 0.5813\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 1.2621 Acc: 0.5547\n",
            "val Loss: 1.4490 Acc: 0.4750\n",
            "\n",
            "Training complete in 1m 43s\n",
            "Best val Acc: 0.581250\n",
            "128\n",
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 3.2781 Acc: 0.1922\n",
            "nonzero proportion: 0.5961\n",
            "layer 0  new threshold 0.0030\n",
            "val Loss: 1.7467 Acc: 0.4188\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 1.8948 Acc: 0.3813\n",
            "val Loss: 1.3663 Acc: 0.5500\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 1.7605 Acc: 0.4422\n",
            "val Loss: 1.4211 Acc: 0.5188\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 1.7280 Acc: 0.4578\n",
            "val Loss: 1.6304 Acc: 0.4313\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 1.6350 Acc: 0.4625\n",
            "val Loss: 1.4147 Acc: 0.5062\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 1.5983 Acc: 0.4844\n",
            "nonzero proportion: 0.5348\n",
            "layer 0  new threshold 0.0034\n",
            "val Loss: 1.3955 Acc: 0.4500\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 1.5589 Acc: 0.4828\n",
            "val Loss: 1.5611 Acc: 0.5188\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 1.4398 Acc: 0.5250\n",
            "val Loss: 1.1643 Acc: 0.6188\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 1.3194 Acc: 0.5344\n",
            "val Loss: 1.1664 Acc: 0.5563\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 1.3282 Acc: 0.5406\n",
            "val Loss: 1.1917 Acc: 0.5312\n",
            "\n",
            "Training complete in 1m 43s\n",
            "Best val Acc: 0.618750\n",
            "128\n",
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 3.2497 Acc: 0.2219\n",
            "nonzero proportion: 0.4817\n",
            "layer 0  new threshold 0.0038\n",
            "val Loss: 1.9153 Acc: 0.3125\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 1.8259 Acc: 0.4047\n",
            "val Loss: 1.7191 Acc: 0.4125\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 1.6978 Acc: 0.4234\n",
            "val Loss: 1.6983 Acc: 0.4250\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 1.6620 Acc: 0.4438\n",
            "val Loss: 1.4967 Acc: 0.4688\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 1.5459 Acc: 0.5000\n",
            "val Loss: 1.6781 Acc: 0.4250\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 1.5474 Acc: 0.4969\n",
            "nonzero proportion: 0.4355\n",
            "layer 0  new threshold 0.0042\n",
            "val Loss: 1.4494 Acc: 0.4938\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 1.4588 Acc: 0.5094\n",
            "val Loss: 1.9357 Acc: 0.3750\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 1.2984 Acc: 0.5438\n",
            "val Loss: 1.3123 Acc: 0.5000\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 1.2910 Acc: 0.5719\n",
            "val Loss: 1.3520 Acc: 0.5438\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 1.2384 Acc: 0.5500\n",
            "val Loss: 1.3513 Acc: 0.5375\n",
            "\n",
            "Training complete in 1m 43s\n",
            "Best val Acc: 0.543750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gcCzS1xv6nZY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run_normal_training_with_pruning(this_trainset):\n",
        "  model_ft = models.vgg16(pretrained=True)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model_ft = model_ft.to(device)\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model_ft = model_ft.to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  # Observe that all parameters are being optimized\n",
        "  optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "  # Decay LR by a factor of 0.1 every 7 epochs\n",
        "  exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "  freeze_layers(model_ft.features, exclude=[])\n",
        "  mask_network(model_ft.classifier,[0],threshold=0.0001)\n",
        "  set_threshold(model_ft)\n",
        "  \n",
        "  print(this_trainset.__len__())  \n",
        "  _,mytrainset = torch.utils.data.random_split(this_trainset,(49200,800))\n",
        "  # _,trainset = torch.utils.data.random_split(trainset,(49995,5))\n",
        "  print(mytrainset.__len__())\n",
        "\n",
        "  mytrain_data, myval_data = torch.utils.data.random_split(mytrainset,(int(0.8*len(mytrainset)),int(0.2*len(mytrainset))))\n",
        "  print(mytrain_data.__len__(),myval_data.__len__() )\n",
        "\n",
        "  mytrainloader = torch.utils.data.DataLoader(mytrain_data, batch_size=5,\n",
        "                                            shuffle=True, num_workers=0)\n",
        "  myvalloader = torch.utils.data.DataLoader(myval_data, batch_size=5,\n",
        "                                            shuffle=True, num_workers=0)\n",
        "  mydataloaders = {'train': mytrainloader, 'val': myvalloader}\n",
        "  image_datasets= {'train': mytrain_data,'val': myval_data}\n",
        "  dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "  \n",
        "  \n",
        "  model_ft = train_model_prune(model_ft, mydataloaders,dataset_sizes, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=2)\n",
        "  \n",
        "# run_normal_training_with_pruning(trainset)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}