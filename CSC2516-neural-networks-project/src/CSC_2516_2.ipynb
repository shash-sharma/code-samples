{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSC_2516_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asalcedo31/CSC2516_project/blob/master/CSC_2516_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "IFLeFAHicRU5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OPQe-n_jPx_M",
        "colab_type": "code",
        "outputId": "03d8d2fe-c16d-406b-98bc-dc3605d20cb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=5,\n",
        "                                         shuffle=False, num_workers=0)\n",
        "_,trainset = torch.utils.data.random_split(trainset,(49500,500))\n",
        "# _,trainset = torch.utils.data.random_split(trainset,(49995,5))\n",
        "print(trainset.__len__())\n",
        "\n",
        "train_data, val_data = torch.utils.data.random_split(trainset,(int(0.8*len(trainset)),int(0.2*len(trainset))))\n",
        "print(train_data.__len__(),val_data.__len__() )\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=5,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "valloader = torch.utils.data.DataLoader(val_data, batch_size=5,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "\n",
        "# classes = ('plane', 'car', 'bird', 'cat',\n",
        "#            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "500\n",
            "400 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9RYIP8dtZbIO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_datasets= {'train': train_data,'val': val_data}\n",
        "dataloaders = {'train': trainloader, 'val': valloader}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "# class_names = image_datasets['train'].classes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uqvxPLbW599o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def freeze_layers(model_ft, exclude=[]):\n",
        "#   children = list(model_ft.named_children())\n",
        "  for name,param in model_ft.named_parameters():   \n",
        "    if(name not in  exclude):\n",
        "      param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xjclw8yNPoAf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def countNonZeroWeights(model):\n",
        "    nonzeros = 0\n",
        "    weights = 0\n",
        "    for name,param in model.named_parameters():\n",
        "        if param is not None:\n",
        "            nonzeros += torch.sum((param != 0).int()).data[0]\n",
        "            weights += torch.sum(param).data[0]\n",
        "    \n",
        "    return nonzeros, weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jJ9ojdvY0Opu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def set_threshold(model):\n",
        "  for child in model.named_children():    \n",
        "    for child in child[1].named_children():\n",
        "      if type(child[1]) == MaskedLinear: \n",
        "        child[1].set_threshold()\n",
        "        print(\"layer {}  new threshold {:.4f}\".format(child[0], child[1].threshold))        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sB6bCnTUahHw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "#                 dataloader = train_data_loader\n",
        "                model.train()  # Set model to training mode\n",
        "                data_idx = 0\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "#                 dataloader = val_data_loader\n",
        "                data_idx = 1\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            i=0\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "#                 print('i ',i)\n",
        "#                 i+=1\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yGFQgAQBwyBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model_prune(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "#                 dataloader = train_data_loader\n",
        "                model.train()  # Set model to training mode\n",
        "                data_idx = 0\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "#                 dataloader = val_data_loader\n",
        "                data_idx = 1\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            i=0\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "#                 print('i ',i)\n",
        "#                 i+=1\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if epoch % 5 == 0 and phase == 'train':\n",
        "#               countNonZeroWeights(model)\n",
        "              set_threshold(model)                           \n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yxJoz0sd8dLX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MaskedLinear(torch.nn.Linear):\n",
        "  def __init__(self, in_features, out_features, bias=True, threshold=0.1):\n",
        "    super(MaskedLinear, self).__init__(in_features,out_features)\n",
        "    self.make_mask(threshold)    \n",
        "  def make_mask(self, threshold):\n",
        "    self.mask = torch.ones(self.weight.size(), requires_grad=False).to(device)\n",
        "    self.zeros = torch.zeros(self.weight.size(), requires_grad=False).to(device)\n",
        "    self.threshold = threshold    \n",
        "  def set_threshold(self):\n",
        "    unique_weights = torch.unique(self.weight*self.mask)\n",
        "    mask_nonzero = torch.sum(self.mask.view([self.in_features*self.out_features]))\n",
        "    mask_total = self.in_features*self.out_features\n",
        "    print('nonzero proportion: {:.4f}'.format(mask_nonzero/mask_total))\n",
        "    self.threshold = torch.max(torch.topk(torch.abs(unique_weights),int(0.05*unique_weights.size()[0]),largest=False)[0])    \n",
        "  def mask_weight(self):\n",
        "    self.mask = torch.where(torch.abs(self.weight) >= self.threshold,self.mask,self.zeros)\n",
        "    self.weight = torch.nn.Parameter(self.weight*self.mask).to(device)    \n",
        "  def forward(self, input):\n",
        "    self.mask_weight()\n",
        "    return F.linear(input, self.weight, self.bias)\n",
        "\n",
        "def mask_network(network,layers_to_mask, threshold=0.002, random_init=False):\n",
        "  \"\"\"\"\n",
        "  replaces linear layers with masked linear layers\n",
        "  network is the initial sequential container\n",
        "  layers is a list of layers to mask\n",
        "  random init is a logical indicating whether to preserve the initial weights or to modify them\n",
        "  \"\"\"\n",
        "  for name,layer in network.named_children():   \n",
        "    if int(name) in layers_to_mask:\n",
        "      if type(layer)== torch.nn.Linear:\n",
        "        masked_layer = MaskedLinear(layer.in_features, layer.out_features, bias=True,threshold=threshold)\n",
        "      elif type(layer)== torch.nn.Conv2d:\n",
        "        masked_layer = MaskedConv(layer.in_channels, layer.out_channels, layer.kernel_size, layer.stride, layer.padding, layer.dilation, layer.groups, bias=True, threshold=threshold)\n",
        "      if random_init != True:\n",
        "        masked_layer.weight = copy.deepcopy(layer.weight)\n",
        "        masked_layer.bias = copy.deepcopy(layer.bias)\n",
        "      network[int(name)] = masked_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5yXEJeg3cUqt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MaskedConv(torch.nn.Conv2d, MaskedLinear):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride,\n",
        "                 padding, dilation, transposed, output_padding, groups, bias):\n",
        "    super(MaskedConv,self).__init__(self, in_channels, out_channels, kernel_size, stride,\n",
        "                 padding, dilation, transposed, output_padding, groups, bias)\n",
        "    self.make_mask()    \n",
        "  def forward(self, input):\n",
        "    self.mask_weight()\n",
        "    return F.conv2d(input, self.weight, self.bias, self.stride,\n",
        "                    self.padding, self.dilation, self.groups)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BibRv_F3nSDF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "9465505e-a62a-4872-f93e-04637a3d9c29"
      },
      "cell_type": "code",
      "source": [
        "model_ft = models.vgg16(pretrained=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "freeze_layers(model_ft.features, exclude=['28.weight'])\n",
        "freeze_layers(model_ft.classifier)\n",
        "\n",
        "# #baseline\n",
        "# model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "#                        num_epochs=25)\n",
        "\n",
        "mask_network(model_ft.features,[28],threshold=0.0001)\n",
        "set_threshold(model_ft)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-fa9714c1230b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#                        num_epochs=25)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmask_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mset_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-1a5364f5668f>\u001b[0m in \u001b[0;36mmask_network\u001b[0;34m(network, layers_to_mask, threshold, random_init)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mmasked_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskedLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mmasked_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskedConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrandom_init\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mmasked_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'in_channels' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "nqP3jrVtO5pq",
        "colab_type": "code",
        "outputId": "deb8569d-cfb5-4146-9f29-61c0a4065e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1558
        }
      },
      "cell_type": "code",
      "source": [
        "model_ft = train_model_prune(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=26)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/25\n",
            "----------\n",
            "nonzero proportion: 0.9701\n",
            "layer 0  new threshold 0.0004\n",
            "nonzero proportion: 0.9549\n",
            "layer 3  new threshold 0.0011\n",
            "train Loss: 4.4006 Acc: 0.1875\n",
            "val Loss: 1.9756 Acc: 0.3100\n",
            "\n",
            "Epoch 1/25\n",
            "----------\n",
            "train Loss: 1.8844 Acc: 0.3675\n",
            "val Loss: 1.6459 Acc: 0.4800\n",
            "\n",
            "Epoch 2/25\n",
            "----------\n",
            "train Loss: 1.8419 Acc: 0.4075\n",
            "val Loss: 1.6798 Acc: 0.4000\n",
            "\n",
            "Epoch 3/25\n",
            "----------\n",
            "train Loss: 1.8904 Acc: 0.4150\n",
            "val Loss: 1.5283 Acc: 0.4500\n",
            "\n",
            "Epoch 4/25\n",
            "----------\n",
            "train Loss: 1.6941 Acc: 0.4700\n",
            "val Loss: 1.3843 Acc: 0.5200\n",
            "\n",
            "Epoch 5/25\n",
            "----------\n",
            "nonzero proportion: 0.9397\n",
            "layer 0  new threshold 0.0005\n",
            "nonzero proportion: 0.9113\n",
            "layer 3  new threshold 0.0016\n",
            "train Loss: 1.6711 Acc: 0.4750\n",
            "val Loss: 1.8568 Acc: 0.4200\n",
            "\n",
            "Epoch 6/25\n",
            "----------\n",
            "train Loss: 1.6418 Acc: 0.4850\n",
            "val Loss: 1.5815 Acc: 0.4600\n",
            "\n",
            "Epoch 7/25\n",
            "----------\n",
            "train Loss: 1.3771 Acc: 0.5550\n",
            "val Loss: 1.4078 Acc: 0.4700\n",
            "\n",
            "Epoch 8/25\n",
            "----------\n",
            "train Loss: 1.4829 Acc: 0.5000\n",
            "val Loss: 1.5295 Acc: 0.4700\n",
            "\n",
            "Epoch 9/25\n",
            "----------\n",
            "train Loss: 1.3231 Acc: 0.5425\n",
            "val Loss: 1.3989 Acc: 0.5200\n",
            "\n",
            "Epoch 10/25\n",
            "----------\n",
            "nonzero proportion: 0.9093\n",
            "layer 0  new threshold 0.0007\n",
            "nonzero proportion: 0.8693\n",
            "layer 3  new threshold 0.0021\n",
            "train Loss: 1.3772 Acc: 0.5550\n",
            "val Loss: 1.4916 Acc: 0.4700\n",
            "\n",
            "Epoch 11/25\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-e8ed347b3d65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_ft = train_model_prune(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m----> 2\u001b[0;31m                        num_epochs=26)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-0f1d4e29a050>\u001b[0m in \u001b[0;36mtrain_model_prune\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#                 i+=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oiU5oOZpOG_8",
        "colab_type": "code",
        "outputId": "2618fcff-2141-43a5-802b-28083f7af3be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "model_ft = models.vgg16(pretrained=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "\n",
        "freeze_conv_layers(model_ft)\n",
        "mask_network(model_ft.classifier,[0,3],threshold=0.0001)\n",
        "set_threshold(model_ft)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nonzero proportion: 1.0000\n",
            "layer 0  new threshold 0.0002\n",
            "nonzero proportion: 1.0000\n",
            "layer 3  new threshold 0.0005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ez6FqzjW3p0I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#testing code ignore\n",
        "model_ft = models.vgg16(pretrained=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "mask_network(model_ft.classifier,[0,3,6])\n",
        "# print(model_ft.classifier)\n",
        "# print(model_ft.classifier[0].weight[120:130,120::130])\n",
        "print(model_ft.classifier[0].threshold)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kL4TQgkfF762",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#testing code ignore\n",
        "i=0\n",
        "for inputs,labels in dataloaders['train']:\n",
        "  inputs = inputs.to(device)\n",
        "  model_ft.eval()  \n",
        "  outputs = model_ft(inputs)\n",
        "#   print(model_ft.classifier[3].threshold)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r4zZe_zdbtDj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#baseline\n",
        "model_ft = models.vgg16(pretrained=True)\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "# model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# model_ft = models.resnet18(pretrained=True)\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "# model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRnWj3VTb_6d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#baseline\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KH7W8TocSOS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "f73c97c4-c134-4530-e6b8-209047415bbd"
      },
      "cell_type": "code",
      "source": [
        "print((model_ft.features))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace)\n",
            "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): ReLU(inplace)\n",
            "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (6): ReLU(inplace)\n",
            "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace)\n",
            "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): ReLU(inplace)\n",
            "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace)\n",
            "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): ReLU(inplace)\n",
            "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (18): ReLU(inplace)\n",
            "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (20): ReLU(inplace)\n",
            "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (22): ReLU(inplace)\n",
            "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (25): ReLU(inplace)\n",
            "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (27): ReLU(inplace)\n",
            "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (29): ReLU(inplace)\n",
            "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oxDGbJJMQBlP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "children = list(model_ft.named_children())\n",
        "# print(list(children[0][1].named_parameters())[0])\n",
        "# print(list(children[2][1].named_parameters())[0])\n",
        "inpurs\n",
        "print(children[2][1][0].weight)\n",
        "# for name,param in children[2][1].named_parameters():\n",
        "#   print(name)\n",
        "#   print(param)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BLGNpub8gYd7",
        "colab_type": "code",
        "outputId": "19f7d10a-11cc-4d36-b9c0-e23fcfcda6a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1619
        }
      },
      "cell_type": "code",
      "source": [
        "children = list(model_ft.named_children())\n",
        "print(list(children[0][1].named_parameters())[0])\n",
        "print(list(children[2][1].named_parameters())[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('0.weight', Parameter containing:\n",
            "tensor([[[[-5.5373e-01,  1.4270e-01,  5.2896e-01],\n",
            "          [-5.8312e-01,  3.5655e-01,  7.6566e-01],\n",
            "          [-6.9022e-01, -4.8019e-02,  4.8409e-01]],\n",
            "\n",
            "         [[ 1.7548e-01,  9.8630e-03, -8.1413e-02],\n",
            "          [ 4.4089e-02, -7.0323e-02, -2.6035e-01],\n",
            "          [ 1.3239e-01, -1.7279e-01, -1.3226e-01]],\n",
            "\n",
            "         [[ 3.1303e-01, -1.6591e-01, -4.2752e-01],\n",
            "          [ 4.7519e-01, -8.2677e-02, -4.8700e-01],\n",
            "          [ 6.3203e-01,  1.9308e-02, -2.7753e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3254e-01,  1.2666e-01,  1.8605e-01],\n",
            "          [-4.2805e-01, -2.4349e-01,  2.4628e-01],\n",
            "          [-2.5066e-01,  1.4177e-01, -5.4864e-03]],\n",
            "\n",
            "         [[-1.4076e-01, -2.1903e-01,  1.5041e-01],\n",
            "          [-8.4127e-01, -3.5176e-01,  5.6398e-01],\n",
            "          [-2.4194e-01,  5.1928e-01,  5.3915e-01]],\n",
            "\n",
            "         [[-3.1432e-01, -3.7048e-01, -1.3094e-01],\n",
            "          [-4.7144e-01, -1.5503e-01,  3.4589e-01],\n",
            "          [ 5.4384e-02,  5.8683e-01,  4.9580e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7715e-01,  5.2149e-01,  9.8740e-03],\n",
            "          [-2.7185e-01, -7.1709e-01,  3.1292e-01],\n",
            "          [-7.5753e-02, -2.2079e-01,  3.3455e-01]],\n",
            "\n",
            "         [[ 3.0924e-01,  6.7071e-01,  2.0546e-02],\n",
            "          [-4.6607e-01, -1.0697e+00,  3.3501e-01],\n",
            "          [-8.0284e-02, -3.0522e-01,  5.4460e-01]],\n",
            "\n",
            "         [[ 3.1572e-01,  4.2335e-01, -3.4976e-01],\n",
            "          [ 8.6354e-02, -4.6457e-01,  1.1803e-02],\n",
            "          [ 1.0483e-01, -1.4584e-01, -1.5765e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 7.7599e-02,  1.2692e-01,  3.2305e-02],\n",
            "          [ 2.2131e-01,  2.4681e-01, -4.6637e-02],\n",
            "          [ 4.6407e-02,  2.8246e-02,  1.7528e-02]],\n",
            "\n",
            "         [[-1.8327e-01, -6.7425e-02, -7.2120e-03],\n",
            "          [-4.8855e-02,  7.0427e-03, -1.2883e-01],\n",
            "          [-6.4601e-02, -6.4566e-02,  4.4235e-02]],\n",
            "\n",
            "         [[-2.2547e-01, -1.1931e-01, -2.3425e-02],\n",
            "          [-9.9171e-02, -1.5143e-02,  9.5385e-04],\n",
            "          [-2.6137e-02,  1.3567e-03,  1.4282e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6520e-02, -3.2225e-02, -3.8450e-03],\n",
            "          [-6.8206e-02, -1.9445e-01, -1.4166e-01],\n",
            "          [-6.9528e-02, -1.8340e-01, -1.7422e-01]],\n",
            "\n",
            "         [[ 4.2781e-02, -6.7529e-02, -7.0309e-03],\n",
            "          [ 1.1765e-02, -1.4958e-01, -1.2361e-01],\n",
            "          [ 1.0205e-02, -1.0393e-01, -1.1742e-01]],\n",
            "\n",
            "         [[ 1.2661e-01,  8.5046e-02,  1.3066e-01],\n",
            "          [ 1.7585e-01,  1.1288e-01,  1.1937e-01],\n",
            "          [ 1.4656e-01,  9.8892e-02,  1.0348e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 3.2176e-02, -1.0766e-01, -2.6388e-01],\n",
            "          [ 2.7957e-01, -3.7416e-02, -2.5471e-01],\n",
            "          [ 3.4872e-01,  3.0041e-02, -5.5898e-02]],\n",
            "\n",
            "         [[ 2.5063e-01,  1.5543e-01, -1.7432e-01],\n",
            "          [ 3.9255e-01,  3.2306e-02, -3.5191e-01],\n",
            "          [ 1.9299e-01, -1.9898e-01, -2.9713e-01]],\n",
            "\n",
            "         [[ 4.6032e-01,  4.3399e-01,  2.8352e-01],\n",
            "          [ 1.6341e-01, -5.8165e-02, -1.9196e-01],\n",
            "          [-1.9521e-01, -4.5630e-01, -4.2732e-01]]]], device='cuda:0'))\n",
            "('0.weight', Parameter containing:\n",
            "tensor([[-0.0012, -0.0027,  0.0024,  ...,  0.0067, -0.0004, -0.0021],\n",
            "        [ 0.0053,  0.0020,  0.0045,  ..., -0.0053, -0.0045, -0.0019],\n",
            "        [-0.0005,  0.0052,  0.0018,  ...,  0.0068,  0.0005,  0.0091],\n",
            "        ...,\n",
            "        [-0.0075, -0.0096, -0.0025,  ..., -0.0079, -0.0106, -0.0036],\n",
            "        [-0.0006,  0.0014, -0.0019,  ...,  0.0036,  0.0021,  0.0038],\n",
            "        [ 0.0063,  0.0041, -0.0004,  ..., -0.0030,  0.0011,  0.0048]],\n",
            "       device='cuda:0', requires_grad=True))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xNEXN_IpNDVM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://discuss.pytorch.org/t/find-non-zero-elements-in-a-tensor/4493/2"
      ]
    }
  ]
}